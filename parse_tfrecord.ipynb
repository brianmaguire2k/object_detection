{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse created TFRecords to check a few images\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from data_decoders import tf_example_decoder\n",
    "import utils.visualization_utils as viz_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_path = 'data/train.record' # path to TFRecord file\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_path) # convert to dataset for parsing\n",
    "decoder = tf_example_decoder.TfExampleDecoder() # decoder for PASCAL VOC format TFRecords\n",
    "\n",
    "category_index = {\n",
    "    1: {'id': 1, 'name': 'truck'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over examples in dataset and plot image/bounding box using OD API viz_utils\n",
    "n_ims = 5 # stop after five for now\n",
    "\n",
    "for idx, example in enumerate(dataset.as_numpy_iterator()):\n",
    "    im_dict = decoder.decode(example) # decode image to dictionary\n",
    "    im_np = im_dict['image'].numpy() # convert image data to numpy array\n",
    "\n",
    "    # see object_detection/utils/visualization_utils.py for details...\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(image=im_np,\n",
    "            boxes=im_dict['groundtruth_boxes'].numpy(), \n",
    "            classes=im_dict['groundtruth_classes'].numpy().astype(np.int32), \n",
    "            scores=np.ones(1),\n",
    "            category_index=category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=1)\n",
    "\n",
    "    # create figure and show image\n",
    "    plt.figure()\n",
    "    plt.imshow(im_np)\n",
    "\n",
    "    # stop after n_ims\n",
    "    if idx >= (n_ims - 1):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking size of image, values for other im_dict keys\n",
    "for kk in im_dict.keys():\n",
    "    if kk == 'image':\n",
    "        print(f'{kk} dimensions = {im_dict[kk].shape}')\n",
    "    else:\n",
    "        print(f'{kk} = {im_dict[kk]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing bounding boxes to see size of targets in image\n",
    "im_sz = (1024, 540) # (w, h)\n",
    "scale = 640./1024. # images resized to 640x640 with padding\n",
    "\n",
    "tgt_sz = np.zeros(shape=(360, 2))\n",
    "for idx, example in enumerate(dataset.as_numpy_iterator()):\n",
    "    im_dict = decoder.decode(example)\n",
    "\n",
    "    # bboxes are [ymin, xmin, ymax, xmax] in normalized coordinates\n",
    "    bbox_tf = im_dict['groundtruth_boxes'].numpy()[0]\n",
    "\n",
    "    tgt_sz[idx, 1] = (bbox_tf[2] - bbox_tf[0])*im_sz[1]\n",
    "    tgt_sz[idx, 0] = (bbox_tf[3] - bbox_tf[1])*im_sz[0]\n",
    "\n",
    "print(np.mean(tgt_sz*scale, axis=0))\n",
    "print(np.max(tgt_sz*scale, axis=0))\n",
    "print(np.min(tgt_sz*scale, axis=0))"
   ]
  }
 ]
}